The emergence of new architectures like the cloud opens new opportunities to data processing. 
The possibility of having unlimited access to cloud resources and the ``pay as U go'' model make it possible to change the hypothesis for processing big  data collections.  Instead of designing processes and algorithms taking into consideration  limitations on resources availability, the cloud sets the focus on the economic cost implied when using resources and producing results by parallelizing their use while delivering data under subscription oriented cost models.
 
Integrating and processing heterogeneous Big Data calls for efficient methods for correlating, associating, filtering them taking into consideration their ``structural'' characteristics (due to data variety) but also their quality (veracity), e.g., trust, freshness, provenance, partial or total consistency. 
Existing data integration techniques need to be revisited considering weakly curated and modeled data sets provided by different services under different quality conditions. Data integration can be done according to quality of service (QoS) requirements expressed by their consumers and Service Level Agreements (SLA)  exported by the cloud providers that host  Big Data and deliver resources for executing the associated management processes. Yet, it is not an easy task to completely enforce SLAs particularly because consumers use several cloud providers to store, integrate and process the data they require under the specific conditions they expect.
Naturally, a collaboration between cloud providers becomes necessary~\cite{036} but this should be also done in a user-friendly way, with some degree of transparency. 

To better understand, let us consider an example from the domain of energy
management. We assume we are interested in queries like: \textit{Give a list
of energy providers that can provision 1000 KW-h, in the next 10 seconds, that are close to my city, with a cost of 0,50 Euro/KW-h and that are labeled as green?} We consider a simplified SLA cloud contract inspired in the cheapest contract provided by Azure: \textit{cost of \$0,05 cents per call,  8~GB of I/O volume/month, free data transfer cost within the same region,  1~GB of storage.} 
Suppose that the user is ready to pay a maximum of \textit{\$5 as total query cost}; she requests that only  \textit{green} energy providers should be  listed (provenance), with at least  \textit{85$\%$} of precision of provided data, even if they are not fresh; she requires an availability rate of at least 90$\%$ and a response time of  \textit{0,01 s}. 
  The question is how can the user efficiently obtain  results for her queries such that they meet her QoS requirements, they respect her subscribed contracts with the involved cloud provider(s) and such that they do not neglect services contracts? 
  %Particularly, for queries that call several services deployed  on different clouds.

%\subsection{Contribution}
Data integration has to be revisited according to  the properties of data collections (volume, variety, velocity), to service oriented data provision contexts normally done in the context of cloud environments. Such environments (multi-cloud)  provide the required storage, computing and processing resources but that call for new strategies for integrating data considering different SLAs, subscription conditions, and data consumption requirements and preferences. In this context, the contribution of our work is two-fold. First it proposes a classification scheme of existing works fully or partially addressing the problem of integrating data in multi-cloud environments eventually taking into consideration Service Level Agreement. Second, an approach for guiding data integration in multi-cloud environments  by SLA and user/applications preferences. 

The classification scheme results from  applying the  methodology defined in~\cite{SM:Petersen:2008} called  \textit{systematic mapping}  for defining a classification of a field. A classification consists of categories clustered into facets in which publication are aggregated according to frequencies. According to the methodology, the study consists in  five interdependent tasks including (i) the definition of a research scope by defining research questions; (ii) retrieving candidate papers by querying different scientific databases (e.g. IEEE, Citeseer, DBLP); (iii) selecting relevant papers that can be used for answering the research questions by defining inclusion and exclusion criteria; (iv) defining a classification scheme by analyzing the abstracts of the selected papers to identify the terms that will be used as categories for classifying the papers; (v) producing a systematic mapping by sorting papers according to the classification scheme. 

Our final objective by applying the systematic mapping methodology is to identify trends and open issues regarding our research topic. Thus, our classification scheme consists in three facets that classify existing scientific publications addressing  together or independently SLA, Data Integration in Multi-cloud environments and two additional ones to identify the type of papers (e.g., position, survey, etc) and the type of contribution (e.g., model, architecture, system). It shows the research trends of data integration as a result of the emergence of the cloud and the characteristics associated to Big Data that require resources in order to be processed,  and to propose our vision for filling some gaps and propose an original data integration solution according to current trends in the area. 


%\subsection{Organization of the paper}
The remainder of this paper is organized as follows. 
Section~\ref{sec:sm} describes our study of  data integration perspectives and the evolution of the research works that address some aspects of the problem. The section gives a quantitative analysis of our study and identifies open issues in the field. Section \ref{sec:approach} gives the general lines of the approach we propose for guiding data integration using SLA agreements in a multi-cloud environment. We show initial experiments that show the feasibility of our approach.  Section~\ref{sec:rw} discusses existing approaches studying data integration problems in multi-cloud contexts that take into account SLA contacts and that are supported by cloud providers for providing efficient solutions when the data collections they deal with are close to some Big Data properties: volume, variety, velocity, veracity, etc.
Section~\ref{sec:conc} concludes the paper and discusses future work. 


